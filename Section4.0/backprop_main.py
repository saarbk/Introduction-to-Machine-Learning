import numpy as npimport backprop_dataimport matplotlib.pyplot as pltimport backprop_network# plt.rcParams['text.usetex'] = Truetraining_data, test_data = backprop_data.load(train_size=10000, test_size=5000)"""             Q-1"""net = backprop_network.Network([784, 40, 10])net.SGD(training_data, epochs=30, mini_batch_size=10, learning_rate=0.1, test_data=test_data)"""             Q-2"""rates = [0.001, 0.01, 0.1, 1, 10, 100]train_accuracy = [None] * 6train_loss = [None] * 6test_accuracy = [None] * 6for i in range(6):    net = backprop_network.Network([784, 40, 10])    train_accuracy[i], train_loss[i], test_accuracy[i] = net.SGD(training_data, epochs=30, mini_batch_size=10,                                                                 learning_rate=rates[i], test_data=test_data)    print("finished rate " + str(rates[i]))for i in range(6):    plt.plot(np.arange(30), train_accuracy[i], label=r"rate = {}".format(rates[i]))plt.xlabel(r"epochs", fontsize=13)plt.ylabel(r"accuracy", fontsize=13)plt.title(r"\bf{$Training$ accuracy}", fontsize=19)plt.legend()plt.show()for i in range(6):    plt.plot(np.arange(30), train_loss[i], label="rate = {}".format(rates[i]))plt.xlabel(r"epochs", fontsize=13)plt.ylabel(r"$\ell (\mathcal{W})$", fontsize=13)plt.title(r"\bf{$Training$ loss $\ell (\mathcal{W})$ }", fontsize=19)plt.legend()plt.show()for i in range(6):    plt.plot(np.arange(30), test_accuracy[i], label="rate = {}".format(rates[i]))plt.xlabel(r"epochs", fontsize=13)plt.ylabel(r"accuracy", fontsize=13)plt.title(r"\bf{$Test$ loss }", fontsize=19)plt.legend()plt.show()"""             Q-3"""net.SGD(training_data, epochs=30, mini_batch_size=10, learning_rate=0.1, test_data=test_data)